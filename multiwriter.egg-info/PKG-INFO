Metadata-Version: 2.4
Name: multiwriter
Version: 0.1.0
Summary: Multi-Agent AI Novel Outline Generator
Home-page: 
Author: MultiWriter Team
Author-email: 
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: pydantic>=2.5.0
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-community>=0.0.20
Requires-Dist: ollama>=0.1.0
Requires-Dist: boto3>=1.34.0
Requires-Dist: qdrant-client>=1.7.0
Requires-Dist: neo4j>=5.15.0
Requires-Dist: click>=8.1.7
Requires-Dist: rich>=13.7.0
Requires-Dist: aiohttp>=3.9.0
Requires-Dist: pyyaml>=6.0.1
Provides-Extra: dev
Requires-Dist: pytest>=7.4.3; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.1; extra == "dev"
Requires-Dist: black>=23.12.0; extra == "dev"
Requires-Dist: mypy>=1.7.0; extra == "dev"
Dynamic: requires-python

# MultiWriter - Multi-Agent Novel Outline Generator

A scalable multi-agent AI system that generates comprehensive novel outlines with plot structure, characters, world-building, and scene beats.

## Architecture

This system uses specialized AI agents that collaborate like a writers' room:
- **Narrative Architect**: Story structure and plot beats
- **Theme & Premise**: Thematic coherence
- **Character Psychodynamics**: Character profiles and arcs
- **Worldbuilding**: World rules and consistency
- **Scene Dynamics**: Scene breakdowns

## Setup Status

- [x] Python virtual environment created (`venv/`)
- [x] Python dependencies installed
- [x] Configuration file ready (`config/config.yaml`)
- [ ] Ollama installed and running (see below)
- [ ] LLM model pulled

## Quick Start

### 1. Install Ollama (One-time setup)

Download and install Ollama for Windows from: https://ollama.com/download

After installation, Ollama runs automatically as a background service.

### 2. Pull the LLM Model (One-time setup)

Open a terminal and run:
```bash
ollama pull qwen2.5:14b
```

This downloads the Qwen 2.5 14B model (~9GB). Wait for the download to complete.

### 3. Run the CLI

Activate the virtual environment and run:
```powershell
.\venv\Scripts\Activate.ps1
python -m src.cli.main
```

Follow the interactive prompts to provide:
- Novel premise
- Genre
- Key elements
- Character concepts

The system will generate a complete outline saved as Markdown in the `output/` directory.

## Alternative Models

You can use different Ollama models by editing `config/config.yaml`:

| Model | Size | VRAM Required |
|-------|------|---------------|
| `qwen2.5:14b` (default) | ~9GB | ~10GB |
| `llama3.1:8b` | ~4.7GB | ~6GB |
| `mistral-nemo:12b` | ~7GB | ~8GB |
| `llama3.1:70b` | ~40GB | ~48GB |

## Optional: Vector Store (Qdrant)

For enhanced semantic search capabilities, you can run Qdrant via Docker:

```bash
docker-compose up -d qdrant
```

This is optional for basic usage.

## Development

Run tests:
```bash
pytest tests/
```

Format code:
```bash
black src/ tests/
```

Type checking:
```bash
mypy src/
```

## License

Proprietary
